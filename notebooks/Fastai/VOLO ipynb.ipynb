{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 9885 images\n",
      "The mean Pawpularity score is 38.049974709155286\n",
      "The median Pawpularity score is 33.0\n",
      "The standard deviation of the Pawpularity score is 20.599054723289793\n",
      "There are 100 unique values of Pawpularity score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\anaconda\\envs\\tensorflow2\\lib\\site-packages\\albumentations\\augmentations\\transforms.py:1701: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast\n",
      "  FutureWarning,\n",
      "F:\\anaconda\\envs\\tensorflow2\\lib\\site-packages\\albumentations\\augmentations\\transforms.py:1727: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\anaconda\\envs\\tensorflow2\\lib\\site-packages\\albumentations\\augmentations\\transforms.py:1727: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast\n",
      "  FutureWarning,\n",
      "F:\\anaconda\\envs\\tensorflow2\\lib\\site-packages\\albumentations\\augmentations\\transforms.py:1701: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "volo_d2-384: 512\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n",
      "lr\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/12 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>petfinder_rmse</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='725' class='' max='1977' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      36.67% [725/1977 04:28<07:44 0.6713]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"volo_petfinder.ipynb\n",
    "\n",
    "Automatically generated by Colaboratory.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1HwTfmBLJHzaCv0O3X4BpGBMJCoiWCkgB\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import torch\n",
    "torch.__version__\n",
    "\n",
    "import os, sys, gc\n",
    "sys.path.insert(0,r\"F:\\Pycharm_projects\\PetFinder\\models\\VOLO/\")\n",
    "\n",
    "import typing as tp\n",
    "import albumentations as A\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import timm\n",
    "from timm import create_model\n",
    "#from timm.data.mixup import Mixup\n",
    "\n",
    "from fastai.vision.all import *\n",
    "#from fastai.callback.hook import *\n",
    "from volo.models import volo_d1, volo_d2, volo_d3, volo_d4, volo_d5  # register models to timm\n",
    "from volo.utils import load_pretrained_weights as volo_load_weights\n",
    "from fastai.callback.all import *\n",
    "VOLO_CHECHPOINTS = {\n",
    "    \"volo_d1\": \"F:\\Pycharm_projects\\PetFinder\\models\\VOLO/d1_224_84.2.pth.tar\",\n",
    "    \"volo_d1-384\": \"F:\\Pycharm_projects\\PetFinder\\models\\VOLO/d1_384_85.2.pth.tar\",\n",
    "    \"volo_d2\": \"F:\\Pycharm_projects\\PetFinder\\models\\VOLO/d2_224_85.2.pth.tar\",\n",
    "    \"volo_d2-384\": \"F:\\Pycharm_projects\\PetFinder\\models\\VOLO/d2_384_86.0.pth.tar\",\n",
    "    \"volo_d3\": \"..F:\\Pycharm_projects\\PetFinder\\models\\VOLO/d3_224_85.4.pth.tar\",\n",
    "    \"volo_d3-448\": \"F:\\Pycharm_projects\\PetFinder\\models\\VOLO/d3_448_86.3.pth.tar\",\n",
    "    \"volo_d4\": \"F:\\Pycharm_projects\\PetFinder\\models\\VOLO/d4_224_85.7.pth.tar\",\n",
    "    \"volo_d4-448\": \"F:\\Pycharm_projects\\PetFinder\\models\\VOLO/d4_448_86.79.pth.tar\",\n",
    "    \"volo_d5\": \"F:\\Pycharm_projects\\PetFinder\\models\\VOLO/d5_224_86.10.pth.tar\",\n",
    "    \"volo_d5-448\": \"F:\\Pycharm_projects\\PetFinder\\models\\VOLO/d5_448_87.0.pth.tar\",\n",
    "    \"volo_d5-512\": \"F:\\Pycharm_projects\\PetFinder\\models\\VOLO/d5_512_87.07.pth.tar\",\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "class BasicImageModel(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 base_name: str,\n",
    "                 dims_head: tp.List[int],\n",
    "                 pretrained=True,\n",
    "                 in_channels: int=3,\n",
    "                 image_size: int=224,\n",
    "                 drop_path_rate: float=0.1\n",
    "    ):\n",
    "        \"\"\"Initialize\"\"\"\n",
    "        self.base_name = base_name\n",
    "        super().__init__()\n",
    "        model_name = base_name.split(\"-\")[0]\n",
    "        assert timm.is_model(model_name), \"you can use only models in timm.\"\n",
    "\n",
    "        if model_name[:4] == \"volo\":\n",
    "            base_model = timm.create_model(\n",
    "                model_name, img_size=image_size,\n",
    "                mix_token=False,\n",
    "                return_dense=False,\n",
    "                drop_path_rate=0.3, # 0.4,  0.1\n",
    "            )\n",
    "            in_features = base_model.head.in_features\n",
    "            if pretrained:\n",
    "                volo_load_weights(base_model, VOLO_CHECHPOINTS[base_name], strict=False)\n",
    "\n",
    "            if in_channels != 3:\n",
    "                # # change input channel\n",
    "                # # I follow the manner used in timm.\n",
    "                first_conv = base_model.patch_embed.conv[0]\n",
    "                w_t = first_conv.weight.data  # shape: (out_ch, 3, 7, 7)\n",
    "                if in_channels == 1:\n",
    "                    new_w_t = w_t.sum(axis=1, keepdims=True)  # shape: (out_ch, 1, 7, 7)\n",
    "                else:\n",
    "                    n_repeats = (in_channels + 3 - 1) // 3\n",
    "                    new_w_t = w_t.repeat((1, n_repeats, 1, 1))\n",
    "                    new_w_t = new_w_t[:, :in_channels]\n",
    "                    new_w_t = new_w_t * 3 / in_channels  # shape: (out_ch, in_channels, 7, 7)\n",
    "\n",
    "                first_conv.weight.data = new_w_t\n",
    "        else:\n",
    "            base_model = timm.create_model(\n",
    "                base_name, pretrained=pretrained, in_chans=in_channels)\n",
    "            in_features = base_model.num_features\n",
    "            print(\"load imagenet pretrained:\", pretrained)\n",
    "\n",
    "        base_model.reset_classifier(num_classes=0)\n",
    "        self.backbone = base_model\n",
    "        print(f\"{base_name}: {in_features}\")\n",
    "\n",
    "        # # prepare head clasifier\n",
    "        if dims_head[0] is None:\n",
    "            dims_head[0] = in_features\n",
    "\n",
    "        layers_list = []\n",
    "        for i in range(len(dims_head) - 2):\n",
    "            in_dim, out_dim = dims_head[i: i + 2]\n",
    "            layers_list.extend([\n",
    "                nn.Linear(in_dim, out_dim),\n",
    "                nn.ReLU(), nn.Dropout(0.5),])\n",
    "        layers_list.append(\n",
    "            nn.Linear(dims_head[-2], dims_head[-1]))\n",
    "        self.head = nn.Sequential(*layers_list)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward\"\"\"\n",
    "        h = self.backbone(x)\n",
    "        h = self.head(h)\n",
    "        return h\n",
    "\n",
    "seed=365\n",
    "set_seed(seed, reproducible=True)\n",
    "# set_seed(365, reproducible=True)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.use_deterministic_algorithms = True\n",
    "\n",
    "BATCH_SIZE = 4 # 8\n",
    "N_EPOCHS = 12 # 6,7\n",
    "NEED_TRAIN = True\n",
    "\n",
    "dataset_path = Path(r'F:\\Pycharm_projects\\PetFinder\\data\\train')\n",
    "\n",
    "train_df = pd.read_csv('F:\\Pycharm_projects\\PetFinder\\data/train_5folds.csv')\n",
    "train_df['path'] = train_df['Id'].map(lambda x: str(dataset_path/x) + '.jpg')\n",
    "train_df = train_df.drop(columns=['Id'])\n",
    "train_df = train_df.sample(frac=1).reset_index(drop=True) #shuffle dataframe\n",
    "train_df.head()\n",
    "\n",
    "len_df = len(train_df)\n",
    "print(f\"There are {len_df} images\")\n",
    "\n",
    "train_df['Pawpularity'].hist(figsize = (10, 5))\n",
    "print(f\"The mean Pawpularity score is {train_df['Pawpularity'].mean()}\")\n",
    "print(f\"The median Pawpularity score is {train_df['Pawpularity'].median()}\")\n",
    "print(f\"The standard deviation of the Pawpularity score is {train_df['Pawpularity'].std()}\")\n",
    "\n",
    "print(f\"There are {len(train_df['Pawpularity'].unique())} unique values of Pawpularity score\")\n",
    "\n",
    "train_df['norm_score'] = train_df['Pawpularity']/100\n",
    "train_df['norm_score']\n",
    "\n",
    "def petfinder_rmse(input,target):\n",
    "    return 100*torch.sqrt(F.mse_loss(torch.sigmoid(input.flatten()), target))\n",
    "\n",
    "#!pip install radam\n",
    "\n",
    "from radam import Over9000\n",
    "\n",
    "\n",
    "\n",
    "def WrapperOver9000(param_groups,**kwargs):\n",
    "    return OptimWrapper(param_groups,Over9000)\n",
    "project_id = 'volo_d2-384_with_RandomToneCurve'\n",
    "tboard_path = Path(r'F:\\Pycharm_projects\\PetFinder\\Tensorboard' + project_id)\n",
    "\n",
    "import random\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import albumentations as A\n",
    "\n",
    "\n",
    "def visualize(image):\n",
    "\tplt.figure(figsize=(10, 10))\n",
    "\tplt.axis('off')\n",
    "\tplt.imshow(image)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_aug():\n",
    "\treturn A.Compose([\n",
    "\t\tA.Resize(384, 384),\n",
    "\t\tA.SomeOf([A.RandomContrast((0.6, 0.3)), A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=20),\n",
    "\t\t          A.RandomBrightness(limit=[0.6, 0.3]), A.Flip(), A.Rotate(limit=45), A.Equalize(), A.Sharpen(),\n",
    "\t\t          A.Solarize(196), A.Posterize(), A.Affine(translate_percent=[0.1, 0.1])], n=3)\n",
    "\t])\n",
    "\n",
    "\n",
    "def valid_aug():\n",
    "\treturn A.Compose([\n",
    "\t\tA.Resize(384, 384),\n",
    "\n",
    "\t])\n",
    "\n",
    "\n",
    "class AlbumentationsTransform(RandTransform):\n",
    "\t\"A transform handler for multiple `Albumentation` transforms\"\n",
    "\tsplit_idx, order = None, 2\n",
    "\n",
    "\tdef __init__(self, train_aug, valid_aug):\n",
    "\t\tstore_attr()\n",
    "\n",
    "\tdef before_call(self, b, split_idx):\n",
    "\t\tself.idx = split_idx\n",
    "\n",
    "\tdef encodes(self, img: PILImage):\n",
    "\t\tif self.idx == 0:\n",
    "\t\t\taug_img = self.train_aug(image=np.array(img))['image']\n",
    "\t\telse:\n",
    "\t\t\taug_img = self.valid_aug(image=np.array(img))['image']\n",
    "\t\treturn PILImage.create(aug_img)\n",
    "\n",
    "def get_data(fold):\n",
    "\n",
    "    train_df_f = train_df.copy()\n",
    "    # add is_valid for validation fold\n",
    "    train_df_f['is_valid'] = (train_df_f['kfold'] == fold)\n",
    "    val_idx = train_df_f[train_df_f['is_valid']].index.values\n",
    "\n",
    "    # blocks=(ImageBlock, CategoryBlock), get_y would be standard Pawpularity\n",
    "    dls = DataBlock(blocks=(ImageBlock, RegressionBlock),\n",
    "\t                get_x=ColReader('path'),\n",
    "\t                get_y=ColReader('norm_score'),\n",
    "\t                splitter=IndexSplitter(val_idx),\n",
    "\t                item_tfms=[AlbumentationsTransform(train_aug(), valid_aug())],\n",
    "\t\t\t\t\t\t\t\t\t        batch_tfms=Normalize.from_stats( [0.5183,  0.4835 ,0.4457],[0.2681 ,0.2638, 0.2658])#pass in item_tfms\n",
    "\t                )\n",
    "    paw_dls = dls.dataloaders(train_df_f,\n",
    "\t                          bs=BATCH_SIZE,\n",
    "\t                          num_workers=0,\n",
    "\t                          seed=seed)\n",
    "\n",
    "\n",
    "\n",
    "    return paw_dls#, splitter\n",
    "\n",
    "def get_learner(fold_num):\n",
    "    data = get_data(fold_num)\n",
    "\n",
    "    #model = create_model('swin_large_patch4_window7_224', pretrained=True, num_classes=data.c)\n",
    "    model = BasicImageModel(base_name='volo_d2-384',\n",
    "                            dims_head=[None, 1],\n",
    "                            image_size=384,\n",
    "                            drop_path_rate=0.3)\n",
    "\n",
    "    # alternatives in cbs for regularization: CutMix(1.0), MixUp(0.4) - use only one or the other\n",
    "    learn = Learner(data,\n",
    "                    model,\n",
    "                    loss_func=BCEWithLogitsLossFlat(),\n",
    "                    metrics=AccumMetric(petfinder_rmse),\n",
    "                    cbs=[MixUp(1.0),RandTransform()],\n",
    "                    opt_func=Adam\n",
    "                    #opt_func=ranger,\n",
    "                    #opt_func=partial(WrapperOver9000, eps=1e-4)\n",
    "                   ).to_fp16()\n",
    "\n",
    "\n",
    "    return learn #, splitter\n",
    "\n",
    "auglist = [A.RandomBrightness(),A.RandomGamma(),A.RandomBrightnessContrast()]\n",
    "\n",
    "dls = get_data(0)\n",
    "dls.show_batch()\n",
    "\n",
    "class RandAug(Transform):\n",
    "    def __init__(self,n,m,auglist):\n",
    "        self.auglist = auglist\n",
    "        self.n = n\n",
    "        self.m = m\n",
    "    def encode(self,img: PILImage):\n",
    "        img = np.array(img)\n",
    "        ops = random.choices(self.auglist,k=self.n)\n",
    "        for op,minval,maxval in ops:\n",
    "            val = (float(self.m) / 30) * float(maxval - minval) + minval\n",
    "            img = op(img,val)['image']\n",
    "        return PILImage.create(img)\n",
    "\n",
    "train_df['norm_score'] = train_df['Pawpularity']/100\n",
    "\n",
    "if NEED_TRAIN:\n",
    "    rmse_list = []\n",
    "    ##for i in range(5):\n",
    "    for i in [0,4]:\n",
    "\n",
    "        print(f'Fold {i} results')\n",
    "\n",
    "        learn = get_learner(fold_num=i)\n",
    "        lr = learn.lr_find(end_lr=3e-2)\n",
    "        print(\"training\")\n",
    "\n",
    "        print(\"lr\")\n",
    "\n",
    "        learn.fit_one_cycle(N_EPOCHS, 2e-5/2, cbs=[SaveModelCallback(), EarlyStoppingCallback(monitor='petfinder_rmse', comp=np.less, patience=2)])\n",
    "        learn.recorder.plot_loss()\n",
    "\n",
    "        #over fitting\n",
    "        # learn.unfreeze()\n",
    "\n",
    "        # learn.fit_one_cycle(5,lr_max=slice(1e-6,1e-4))\n",
    "        #learn = learn.to_fp32()\n",
    "\n",
    "        learn.export(f'F:\\Pycharm_projects\\PetFinder\\models/model_fold_{i}.pkl')\n",
    "\n",
    "        #all_preds.append(preds)\n",
    "\n",
    "        val_idx = train_df[train_df['kfold'] == i].index\n",
    "        val_df = train_df.loc[val_idx]\n",
    "\n",
    "        val_pred, _ = learn.get_preds()\n",
    "        val_pred = val_pred.numpy()\n",
    "        val_pred = val_pred * 100\n",
    "\n",
    "        train_df.loc[val_idx, 'oof'] = val_pred\n",
    "        print('Pawpularity vs OOF')\n",
    "        print(val_df['Pawpularity'][:5], val_pred[:5])\n",
    "\n",
    "        real_rmse = mean_squared_error(train_df[train_df['kfold'] == i]['Pawpularity'],\n",
    "                    train_df[train_df['kfold'] == i]['oof'], squared=False)\n",
    "\n",
    "        fold_rmse = mean_squared_error(train_df[train_df['kfold'] == i]['oof'], train_df[train_df['kfold'] == i]['Pawpularity'], squared=False)\n",
    "        print(f'Fold {i} RMSE: {fold_rmse}')\n",
    "        rmse_list.append(fold_rmse)\n",
    "\n",
    "\n",
    "        del learn\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect();\n",
    "\n",
    "print(f'Average Fold RMSE: {sum(rmse_list) / len(rmse_list)}')\n",
    "\n",
    "\n",
    "\n",
    "train_df[['oof','Pawpularity']].plot.scatter('oof','Pawpularity')\n",
    "\n",
    "train_df[['oof','Pawpularity']].hist()\n",
    "\n",
    "train_df.to_csv(f'train_with_oof_seed_{seed}.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"lr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from notebook import notebookapp\n",
    "servers = list(notebookapp.list_running_servers())\n",
    "print(servers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}